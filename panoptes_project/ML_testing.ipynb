{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preamble\n",
    "from astropy.table import Table, column, vstack\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "# better-looking plots\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8)\n",
    "plt.rcParams['font.size'] = 18\n",
    "mpl.ticker.AutoLocator.default_params['nbins'] = 5\n",
    "mpl.ticker.AutoLocator.default_params['prune'] = 'both'\n",
    "\n",
    "mpl.rcParams['ps.useafm'] = True\n",
    "mpl.rcParams['pdf.use14corefonts'] = True\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../astro_codes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "import pandas as pd\n",
    "sparcfire_r = Table.read('../../sparcfire_directories/r/r.galaxy_matched.fits')\n",
    "sparcfire_r_arcs = pd.read_csv('../../sparcfire_directories/r/r.galaxy_arcs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First task: define the sample. How many galaxies do we have?\n",
    "\n",
    "* Load the Spotter data\n",
    "* Check the number of classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from combining_catalogues import match_ids, make_matched_catalogue\n",
    "\n",
    "spotter_subjects = Table.read('../../SpiralSpotter/tables/spiral_spotter_sparcfire_subjects.fits')\n",
    "spotter_data = Table.read('../../SpiralSpotter/tables/spiral_spotter_sparcfire_data.fits')\n",
    "\n",
    "matched_rows = match_ids(spotter_subjects,spotter_data,\n",
    "                         'subject_id','subject_id')\n",
    "\n",
    "matched_data = make_matched_catalogue(spotter_subjects,spotter_data,\n",
    "                                      matched_rows)\n",
    "\n",
    "matched_data['dr7id'] = spotter_subjects['dr7objid']\n",
    "matched_data['dr8id'] = spotter_subjects['dr8objid']\n",
    "matched_data.write('spotter_subjects_matched.fits',overwrite=True)\n",
    "spotter_data = matched_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_ok = []\n",
    "N_classifications = []\n",
    "\n",
    "for N in range(10):\n",
    "    N_ok.append((spotter_data['total'] >= N).sum())\n",
    "    N_classifications.append(N)\n",
    "\n",
    "fig, axarr = plt.subplots(1,2,figsize=(10,5))\n",
    "plt.sca(axarr[0])\n",
    "_ = plt.plot(N_classifications,N_ok,color='k')\n",
    "_ = plt.xlabel('$N_\\mathrm{classifications, \\, min}$')\n",
    "_ = plt.ylabel('$N_\\mathrm{gal}$')\n",
    "\n",
    "class_ok = spotter_data['total'] >= 3\n",
    "plt.sca(axarr[1])\n",
    "_ = plt.hist(spotter_data['total'][class_ok],bins=np.linspace(2.5,9.5,8),\n",
    "             color='k',alpha=0.4)\n",
    "_ = plt.xlabel('$N_\\mathrm{classifications}$')\n",
    "_ = plt.text(0.95,0.95,'$N \\geq{}$ ({} galaxies)'.format(3,class_ok.sum()),\n",
    "             transform=axarr[1].transAxes,ha='right',va='top')\n",
    "\n",
    "spotted_ids = spotter_data['dr8id'][class_ok]\n",
    "spotter_data['class_ok'] = class_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 252 galaxies that have been classified with >= 3 votes. We will now do all of our training on this subset of galaxies.\n",
    "\n",
    "--> **Now, we match up the _p_ scores to their individual arc metadata.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from arc_data import ArcData, ParamikoClient\n",
    "\n",
    "arc_tables = []\n",
    "for id_ in spotted_ids:\n",
    "    arc_tables.append(ArcData(id_).arc_parameters(sparcfire_r_arcs,\n",
    "                                                   sparcfire_r))\n",
    "    \n",
    "arc_table_spotted = vstack(arc_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match_arc_scores(arc_table,galaxy_table,\n",
    "                     arc_id='gxyName',galaxy_id='dr8id'):\n",
    "    labels = ('good','poor','weak','extension','junk','missing')\n",
    "    ids = np.unique(arc_table['gxyName'])\n",
    "    N_arc_rows = len(arc_table)\n",
    "    for label in labels:\n",
    "        arc_table['p_{}'.format(label)] = np.zeros(N_arc_rows,\n",
    "                                                   dtype=np.float16)\n",
    "    for id_ in ids: \n",
    "        masked_arc_rows = arc_table[arc_id] == id_\n",
    "        masked_galaxy_row = galaxy_table[galaxy_id] == id_\n",
    "        arc_rows = arc_table[masked_arc_rows]\n",
    "        galaxy_row = galaxy_table[masked_galaxy_row]\n",
    "        N_arcs = masked_arc_rows.sum()\n",
    "        for label in labels:\n",
    "            column_values = []\n",
    "            for n in range(N_arcs):\n",
    "                column_name = 'arc{}_{}_frac'.format(n+1,label)\n",
    "                arc_column_name = 'p_{}'.format(label)\n",
    "                column_values.append(galaxy_row[column_name][0])\n",
    "            arc_table[arc_column_name][masked_arc_rows] = column_values\n",
    "            \n",
    "    return arc_table\n",
    "\n",
    "arc_table_spotted = match_arc_scores(arc_table_spotted,spotter_data)\n",
    "# ^ this table is a table of 'spotted' galaxies with their corresponding arc \n",
    "# p-values from SpiralSpotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def arc_histogram(ax,data,bins,variable_column,feature_column,\n",
    "                  p=0.5,p_type='threshold',label='good',xlabel='$L$',\n",
    "                  color='r',reference=True):\n",
    "    if p_type is 'threshold':\n",
    "        good_rows = data[feature_column] >= p\n",
    "    else:\n",
    "        good_rows = data[feature_column] == p\n",
    "    bad_rows = good_rows == False\n",
    "    good_label = '$p_\\mathrm{{{}}}>{} \\, (N_\\mathrm{{arcs}}={})$'.format(label,p,\n",
    "                                                           good_rows.sum())\n",
    "    bad_label = '$p_\\mathrm{{{}}}\\leq{} \\, (N_\\mathrm{{arcs}}={})$'.format(label,p,\n",
    "                                                             bad_rows.sum())\n",
    "    if reference is True:\n",
    "        _ = ax.hist(data[variable_column][bad_rows],bins,normed=True,\n",
    "                    color='k',alpha=0.4,label=bad_label)\n",
    "        _ = ax.hist(data[variable_column][bad_rows],bins,normed=True,\n",
    "                    histtype='step',color='k')\n",
    "    _ = ax.hist(data[variable_column][good_rows],bins,normed=True,\n",
    "                histtype='step',color=color,lw=3,label=good_label)\n",
    "    _ = ax.set_xlabel(xlabel)\n",
    "    _ = ax.set_ylabel('normalised density')\n",
    "    #_ = ax.legend(fontsize=15)\n",
    "    return ax\n",
    "\n",
    "arc_params = ['chirality_agreement','arc_length','delta_r',\n",
    "              'pitch_angle_absolute','r_start','r_end',\n",
    "              'relative_theta_end','num_pixels']\n",
    "\n",
    "xlabel_list = ['chiralities agree?','$L$','$\\Delta r$','$\\psi$',\n",
    "               '$r_{start}$','$r_{end}$',r'$\\Delta \\theta$','$N_\\mathrm{pixels}$']\n",
    "\n",
    "fig, axarr = plt.subplots(4,2,figsize=(10,20))\n",
    "axarr = axarr.ravel()\n",
    "for a, arc_param in enumerate(arc_params):\n",
    "    ax = axarr[a]\n",
    "    xlabel = xlabel_list[a]\n",
    "    bins = [-0.5,0.5,1.5]\n",
    "\n",
    "    ax = arc_histogram(ax,arc_table_spotted,None,arc_param,'p_good',\n",
    "                       xlabel=xlabel,color='b')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From an initial runthrough, we can see what the overall parameters are for our good and poor arcs. Generally, good arcs are:\n",
    "\n",
    "- More likely to agree with the dominant chirality\n",
    "- Longer\n",
    "- Cover a wider radial distance\n",
    "- Have pitch angles in the range 10 < $\\psi$ < 30\n",
    "- Start closer to the centre of the galaxy\n",
    "- Wind round a greater distance (cover a bigger range of $\\theta$)\n",
    "- Be comprised of more pixels\n",
    "\n",
    "#### Now: can we use the sklearn methods to tell us whether an arc is true or not?\n",
    "\n",
    "Outr aim here is to use an ML method to train on all of these characteristics and pick out the best arcs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier():\n",
    "    def __init__(self,clf,X,y):\n",
    "        self.X_scaled = StandardScaler().fit_transform(X)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = \\\n",
    "         train_test_split(self.X_scaled,y,test_size=0.25,random_state=0)\n",
    "        self.clf = clf\n",
    "        \n",
    "    def fit(self):\n",
    "        clf.fit(self.X_train,self.y_train)\n",
    "        self.y_probabilities = clf.predict_proba(self.X_test)\n",
    "        self.y_classes = clf.predict(self.X_train)\n",
    "        \n",
    "    def ROC_curve(self,ax,plot=True,probs=np.linspace(0.1,0.9,17),**kwargs):\n",
    "        tp_rates = []\n",
    "        fp_rates = []\n",
    "        for prob in probs:   \n",
    "            y_predicted = self.y_probabilities[:,1] >= prob\n",
    "            tp, fp = self.ROC_rates(y_predicted,self.y_test)\n",
    "            tp_rates.append(tp)\n",
    "            fp_rates.append(fp)\n",
    "        if plot is True:\n",
    "            ax.plot(fp_rates,tp_rates,**kwargs)\n",
    "            ax.set_xlabel('fp rate')\n",
    "            ax.set_ylabel('tp rate')\n",
    "        rates_table = Table(np.array([probs,tp_rates,fp_rates]).T,\n",
    "                            names=('p','tp_rate','fp_rate'))\n",
    "        return rates_table\n",
    "        \n",
    "    def ROC_rates(self,y_predicted,y_true):\n",
    "        true_positive = y_true == 1\n",
    "        true_negative = y_true == 0 \n",
    "        predicted_positive = y_predicted == 1\n",
    "        predicted_negative = y_predicted == 0\n",
    "        tp_rate = (true_positive*predicted_positive).sum()/predicted_positive.sum()\n",
    "        fp_rate = (true_positive*predicted_negative).sum()/predicted_negative.sum()\n",
    "        return tp_rate, fp_rate\n",
    "    \n",
    "    def CC_curve(self,ax,plot=True,probs=np.linspace(0.1,0.9,17),\n",
    "                                            **kwargs):\n",
    "        completenesses = []\n",
    "        contaminations = []\n",
    "        for prob in probs:   \n",
    "            y_predicted = self.y_probabilities[:,1] >= prob\n",
    "            completeness, contamination = completeness_contamination(y_predicted,self.y_test)\n",
    "            completenesses.append(completeness)\n",
    "            contaminations.append(contamination)\n",
    "        efficiencies = [1-c for c in contaminations]\n",
    "        if plot is True:\n",
    "            ax.plot(efficiencies,completenesses,**kwargs)\n",
    "            ax.set_xlabel('efficiency')\n",
    "            ax.set_ylabel('completeness')\n",
    "        rates_table = Table(np.array([probs,completenesses,contaminations]).T,\n",
    "                            names=('p','completeness','efficiency'))\n",
    "        return rates_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the relevant classifiers\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "mlp_parameters = {'alpha':[0.01,0.1,1,10]}\n",
    "svc_parameters =  {'gamma':[0.01,0.1,1,10],'C':[0.01,0.1,1,10]}\n",
    "kn_parameters = {'weights':['uniform','distance'],'p':[1,2]}\n",
    "\n",
    "classifiers = [GridSearchCV(MLPClassifier(random_state=0),\n",
    "                            mlp_parameters),\n",
    "               GaussianNB(),\n",
    "               GridSearchCV(SVC(random_state=0,probability=True),\n",
    "                            svc_parameters),\n",
    "               GridSearchCV(KNeighborsClassifier(),\n",
    "                            kn_parameters),\n",
    "               #GaussianProcessClassifier(random_state=0)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from astroML.utils import completeness_contamination\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "class ArcTable():\n",
    "    def __init__(self,table):\n",
    "        self.table = table\n",
    "        self.arc_params = ('arc_length','delta_r','pitch_angle_absolute',\n",
    "                           'r_start','r_end','relative_theta_end',\n",
    "                           'num_pixels')\n",
    "        \n",
    "    def as_array(self,scaled=True,scaler=None):\n",
    "        X = np.array([self.table[a] for a in self.arc_params]\n",
    "                     ,dtype='float64').T\n",
    "        y = np.array(self.table['p_good'] >= 0.5)#[:,np.newaxis]\n",
    "        chi_mask = self.table['chirality_agreement']\n",
    "        if scaled is True:\n",
    "            X = self.scale(X,scaler)\n",
    "        return X, y, chi_mask\n",
    "    \n",
    "    def scale(self,X,X_scaler=None):\n",
    "        if X_scaler is None:\n",
    "            X_scaled = StandardScaler().fit_transform(X)\n",
    "            return X_scaled\n",
    "        else:\n",
    "            scaler_mean = np.mean(X_scaler,axis=0)\n",
    "            scaler_std = np.std(X_scaler,axis=0)\n",
    "            X_scaled = (X - scaler_mean)/scaler_std\n",
    "            return X_scaled\n",
    "        \n",
    "    def galaxy_split(self,X,y,chi_mask,test_size=52,random_state=0):\n",
    "        ids = self.table['gxyName']\n",
    "        unique_ids = np.unique(ids)\n",
    "        train_ids, test_ids = train_test_split(unique_ids,\n",
    "                                test_size=test_size,random_state=random_state)\n",
    "        \n",
    "        class SplitObject():\n",
    "            def __init__(self,X,y,chi_mask,ids,train_ids,test_ids):\n",
    "                self.train_mask = np.any([ids == id_ for id_ in train_ids],\n",
    "                                         axis=0)\n",
    "                self.test_mask = np.any([ids == id_ for id_ in test_ids],\n",
    "                                        axis=0)\n",
    "                self.X_train = X[self.train_mask]\n",
    "                self.X_test = X[self.test_mask]\n",
    "                self.y_train = y[self.train_mask]\n",
    "                self.y_test = y[self.test_mask]\n",
    "                self.chi_mask_train = chi_mask[self.train_mask]\n",
    "                self.chi_mask_test = chi_mask[self.test_mask]\n",
    "                self.arc_train_ids = ids[self.train_mask] \n",
    "                self.arc_test_ids = ids[self.test_mask]\n",
    "                self.train_ids = train_ids\n",
    "                self.test_ids = test_ids\n",
    "                \n",
    "        return SplitObject(X,y,chi_mask,ids,train_ids,test_ids)\n",
    "    \n",
    "\n",
    "class ClassifyXy():\n",
    "    \n",
    "    def __init__(self,Xy_split):\n",
    "        ClassifyXy.Xy_split = Xy_split\n",
    "        \n",
    "    def fit_and_test_classifier(self,classifier,Xy_split,chi_mask=False):\n",
    "        classifier.fit(Xy_split.X_train,Xy_split.y_train)\n",
    "        y_predicted = classifier.predict(Xy_split.X_test)\n",
    "        if chi_mask is True:\n",
    "            y_predicted[self.Xy_split.chi_mask_test ==  False] = 0\n",
    "        completeness, contamination = completeness_contamination(y_predicted,\n",
    "                                                             Xy_split.y_test)\n",
    "        return completeness, contamination, classifier\n",
    "\n",
    "    def fit_by_n(self,classifier,ax=None,chi_mask=False,\n",
    "                 ticklabels=('$L$','$\\Delta r$','$\\psi$',\n",
    "                             '$r_{start}$','$r_{end}$',\n",
    "                             r'$\\Delta \\theta$','$N_\\mathrm{pixels}$'),\n",
    "                 linestyle='-'):\n",
    "        _ , N_columns = np.shape(self.Xy_split.X_train)\n",
    "        completenesses = []\n",
    "        contaminations = []\n",
    "        N_params = []\n",
    "        for n in range(N_columns):\n",
    "            Xy_split_n = copy.copy(self.Xy_split)\n",
    "            Xy_split_n.X_train = self.Xy_split.X_train[:,:n+1]\n",
    "            Xy_split_n.X_test = self.Xy_split.X_test[:,:n+1]\n",
    "            completeness, contamination, _ = self.fit_and_test_classifier(classifier,\n",
    "                                                                 Xy_split_n,chi_mask)\n",
    "            completenesses.append(completeness)\n",
    "            contaminations.append(contamination)\n",
    "            N_params.append(n+1)\n",
    "        if ax is not None:\n",
    "            ax.plot(completenesses,'bo-',lw=1,linestyle=linestyle)\n",
    "            ax.plot(contaminations,'rs-',lw=3,linestyle=linestyle)\n",
    "            ax.set_xticks(np.arange(N_columns))\n",
    "            ax.set_xticklabels(ticklabels)\n",
    "            ax.set_xlim(-1,N_columns)\n",
    "            ax.set_ylim(0,1)\n",
    "            #ax.legend(fontsize=15,fancybox=False,edgecolor='k')\n",
    "        \n",
    "        output_table = Table(np.array([N_params,completenesses,contaminations]).T,\n",
    "                             names=('N_params','completeness','contamination'))\n",
    "        return output_table\n",
    "\n",
    "    def fit_by_Narcs(self,classifier,ax=None,N_splits=4,chi_mask=False,\n",
    "                     linestyle='-'):\n",
    "        N_rows, _ = np.shape(Xy_split.X_train)\n",
    "        N_arcs = np.linspace(0,N_rows,N_splits+1)\n",
    "        N_arcs = N_arcs[1:].astype(int)\n",
    "        completenesses = []\n",
    "        contaminations = []\n",
    "        for n in N_arcs:\n",
    "            Xy_split_n = copy.copy(self.Xy_split)\n",
    "            Xy_split_n.X_train = self.Xy_split.X_train[:n,:]\n",
    "            Xy_split_n.y_train = self.Xy_split.y_train[:n]\n",
    "            completeness, contamination, _ = self.fit_and_test_classifier(classifier,\n",
    "                                                                 Xy_split_n,chi_mask)\n",
    "            completenesses.append(completeness)\n",
    "            contaminations.append(contamination)\n",
    "        if ax is not None:\n",
    "            ax.plot(N_arcs,completenesses,'bo-',lw=1,linestyle=linestyle)\n",
    "            ax.plot(N_arcs,contaminations,'rs-',lw=3,linestyle=linestyle)\n",
    "            ax.set_ylim(0,1)\n",
    "            #ax.legend(fontsize=15,fancybox=False,edgecolor='k')\n",
    "        \n",
    "        output_table = Table(np.array([N_arcs,completenesses,contaminations]).T,\n",
    "                             names=('N_arcs','completeness','contamination'))\n",
    "        return output_table\n",
    "    \n",
    "    def fit_by_Ngals(self,classifier,ax=None,N_splits=4,chi_mask=False,\n",
    "                     linestyle='-'):\n",
    "        arc_ids = Xy_split.arc_train_ids\n",
    "        unique_ids = np.unique(arc_ids)\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(unique_ids)\n",
    "        N_gal = len(unique_ids)\n",
    "        N_gals = np.linspace(0,N_gal,N_splits+1)\n",
    "        N_gals = N_gals[1:].astype(int)\n",
    "        completenesses = []\n",
    "        contaminations = []\n",
    "        for n in N_gals:\n",
    "            ids_n = unique_ids[:n]\n",
    "            id_mask = np.any([arc_ids == id_ for id_ in ids_n],axis=0)\n",
    "            Xy_split_n = copy.copy(self.Xy_split)\n",
    "            Xy_split_n.X_train = self.Xy_split.X_train[id_mask]\n",
    "            Xy_split_n.y_train = self.Xy_split.y_train[id_mask]\n",
    "            completeness, contamination, _ = self.fit_and_test_classifier(classifier,\n",
    "                                                                 Xy_split_n,chi_mask)\n",
    "            completenesses.append(completeness)\n",
    "            contaminations.append(contamination)\n",
    "        if ax is not None:\n",
    "            ax.plot(N_gals,completenesses,'bo-',lw=1,linestyle=linestyle)\n",
    "            ax.plot(N_gals,contaminations,'rs-',lw=3,linestyle=linestyle)\n",
    "            ax.set_ylim(0,1)\n",
    "            #ax.legend(fontsize=15,fancybox=False,edgecolor='k')\n",
    "        \n",
    "        output_table = Table(np.array([N_gals,completenesses,contaminations]).T,\n",
    "                             names=('N_gals','completeness','contamination'))\n",
    "        return output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, chi_mask = ArcTable(arc_table_spotted).as_array()\n",
    "Xy_split = ArcTable(arc_table_spotted).galaxy_split(X,y,chi_mask,\n",
    "                                                    random_state=2)\n",
    "\n",
    "figlabels = ('MLP','GaussianNB','SVM','KNeighbours')\n",
    "fig, axarr = plt.subplots(2,2,figsize=(10,10))\n",
    "axarr = axarr.ravel()\n",
    "\n",
    "for ax, clf, figlabel in zip(axarr,classifiers,figlabels):\n",
    "    _ = ClassifyXy(Xy_split).fit_by_Ngals(clf,ax,chi_mask=False)\n",
    "    _ = ClassifyXy(Xy_split).fit_by_Ngals(clf,ax,chi_mask=True,linestyle='--')\n",
    "    ax.set_title(figlabel)\n",
    "    \n",
    "fig.text(0.5, 0.04, '$N_\\mathrm{gal}$', ha='center')\n",
    "fig.text(0.04, 0.5, 'statistic', va='center', rotation='vertical')\n",
    "axarr[-1].plot([],[],'bo-',label='completeness')\n",
    "axarr[-1].plot([],[],'rs-',lw=3,label='contamination')\n",
    "\n",
    "# solid line = all chiralities\n",
    "# dashed line = dominant chirality only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now see what the classifier does to a normal subset of galaxies:\n",
    "\n",
    "- Make a plot of true +ve, false +ve, true -ve and false -ve to see where the module is doing well/poorly?\n",
    "\n",
    "First stage here is to fit the model and look at the fractions of fals +ves, false -ves, true +ves and true -ves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_clf = GridSearchCV(SVC(random_state=0,probability=True),\n",
    "                        svc_parameters)\n",
    "# ^Deemed to be the ~tied best classifier according to the ROC+CC analysis\n",
    "\n",
    "_, _, best_clf = ClassifyXy(Xy_split).fit_and_test_classifier(best_clf,\n",
    "                                                         Xy_split,False)\n",
    "\n",
    "y_predicted = best_clf.predict(X)\n",
    "y_predicted[chi_mask == False] = 0\n",
    "arc_table_spotted['p_good_model'] = y_predicted\n",
    "\n",
    "# Now create 'labels' for each of the classifications\n",
    "real_positive = arc_table_spotted['p_good'] >= 0.5\n",
    "real_negative = arc_table_spotted['p_good'] < 0.5\n",
    "predicted_positive = arc_table_spotted['p_good_model'] == 1\n",
    "predicted_negative = arc_table_spotted['p_good_model'] == 0\n",
    "\n",
    "model_labels = np.zeros(len(arc_table_spotted))\n",
    "model_labels[(predicted_positive*real_positive).astype(bool)] = 1 # true +ve\n",
    "model_labels[(predicted_positive*real_negative).astype(bool)] = 2 # false +ve\n",
    "model_labels[(predicted_negative*real_positive).astype(bool)] = 3 # false -ve\n",
    "model_labels[(predicted_negative*real_negative).astype(bool)] = 4 # true -ve\n",
    "arc_table_spotted['model_labels'] = model_labels\n",
    "\n",
    "print('{}/{} good arcs predicted!'.format(y_predicted.sum(),\n",
    "                                          len(y_predicted)))\n",
    "\n",
    "#######################################\n",
    "figure = plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "bins = np.linspace(0.5,4.5,5)\n",
    "_, _ , patches = plt.hist(model_labels,bins)\n",
    "colors = ('limegreen','b','orange','r')\n",
    "for i in range(len(patches)):\n",
    "    patches[i].set_facecolor(colors[i])\n",
    "    patches[i].set_linewidth(1)\n",
    "    patches[i].set_edgecolor('k')\n",
    "\n",
    "xlabels = ('true +ve','false +ve','false -ve','true -ve')\n",
    "_ = ax.set_xticks([1,2,3,4])\n",
    "_ = ax.set_xticklabels(xlabels)\n",
    "_ = ax.set_xlabel('class')\n",
    "_ = ax.set_ylabel('$N_\\mathrm{arcs}$')\n",
    "########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now for the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gz2_data = Table.read('../../fits/full_sample_debiased_w_low_z.fits')\n",
    "# Load the paramiko client i.o.t. get images\n",
    "client = ParamikoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "has_good_arm = [] # only do galaxies where people said there was >= 1 good arm!\n",
    "for id_ in good_ids:\n",
    "    arc_frame_id = arc_table_spotted[arc_table_spotted['gxyName'] == id_]\n",
    "    has_good_arm.append(np.any(arc_frame_id['p_good'] > 0.5))\n",
    "\n",
    "spotter_data['has_good_arm'] = np.zeros(len(spotter_data))\n",
    "spotter_data['has_good_arm'][class_ok] = has_good_arm\n",
    "\n",
    "print('{}/{} galaxies have >1 good arms'.format(np.sum(has_good_arm),\n",
    "                                                len(has_good_arm)))\n",
    "\n",
    "def get_gz2_stats(id_,gz2_data):\n",
    "    m_colnames = ['t11_arms_number_a31_1_debiased_rh',\n",
    "                  't11_arms_number_a32_2_debiased_rh',\n",
    "                  't11_arms_number_a33_3_debiased_rh',\n",
    "                  't11_arms_number_a34_4_debiased_rh',\n",
    "                  't11_arms_number_a36_more_than_4_debiased_rh']\n",
    "    \n",
    "    w_colnames = ['t10_arms_winding_a28_tight_debiased_rh',\n",
    "                  't10_arms_winding_a29_medium_debiased_rh',\n",
    "                  't10_arms_winding_a30_loose_debiased_rh']\n",
    "    \n",
    "    gz2_row = gz2_data[gz2_data['dr8objid'] == id_]\n",
    "    m = np.argmax([gz2_row[c] for c in m_colnames]) + 1\n",
    "    w = np.argmax([gz2_row[c] for c in w_colnames]) + 1\n",
    "    return m, w\n",
    "\n",
    "best_mask = spotter_data['has_good_arm'].astype(bool)\n",
    "best_ids = spotter_data['dr8id'][best_mask]\n",
    "\n",
    "m_list = []\n",
    "w_list = []\n",
    "for id_ in best_ids:\n",
    "    m, w = get_gz2_stats(id_,gz2_data)\n",
    "    m_list.append(m)\n",
    "    w_list.append(w)\n",
    "\n",
    "spotted_gz2_array = np.array([best_ids,m_list,w_list]).T\n",
    "spotted_gz2_table = Table(spotter_gz2_array,names=('id','m','w'),\n",
    "                          dtype=('int64','int','int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def colors_lookup(model_labels):\n",
    "    colors_dictionary = {1:'limegreen',2:'b',3:'orange',4:'r'}\n",
    "    colors_ = []\n",
    "    for ml in model_labels:\n",
    "        color_lookup = colors_dictionary[ml]\n",
    "        colors_.append(color_lookup)\n",
    "    return colors_\n",
    "\n",
    "np.random.seed(0)\n",
    "N_sample_galaxies = 3\n",
    "plot_id_array = np.empty((N_sample_galaxies,4),dtype=np.int64)\n",
    "for m in range(4):\n",
    "    in_m = spotter_gz2_table['m'] == m+2\n",
    "    m_ids = spotter_gz2_table['id'][in_m]\n",
    "    random_ids = np.random.choice(m_ids,N_sample_galaxies,\n",
    "                                  replace=False)\n",
    "    plot_id_array[:,m] = random_ids\n",
    "plot_ids = plot_id_array.ravel()\n",
    "\n",
    "fig, axarr = plt.subplots(3,4,figsize=(20,15))\n",
    "fig.subplots_adjust(hspace=0.05,wspace=0.05)\n",
    "\n",
    "mlabels = ('1','2','3','4','5+')\n",
    "for a, ax in enumerate(axarr[-1,:]):\n",
    "    ax.set_xlabel('$m={}$'.format(mlabels[a+1]))\n",
    "    \n",
    "axarr = axarr.ravel()\n",
    "\n",
    "# Raw images\n",
    "for id_, ax in zip(plot_ids,axarr):\n",
    "    arcplot = ArcData(id_)\n",
    "    arcplot.display_image(ax,client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(3,4,figsize=(20,15))\n",
    "\n",
    "for a, ax in enumerate(axarr[-1,:]):\n",
    "    ax.set_xlabel('$m={}$'.format(mlabels[a+1]))    \n",
    "axarr = axarr.ravel()\n",
    "\n",
    "for id_, ax in zip(plot_ids,axarr):\n",
    "    arcplot = ArcData(id_)\n",
    "    arc_classes = arc_table_spotted[arc_table_spotted['gxyName'] == id_]\n",
    "    model_labels = np.array(arc_classes['model_labels'],dtype=np.int)\n",
    "    colors = colors_lookup(model_labels)\n",
    "    arcplot.display_image(ax,client=client)\n",
    "    arcplot.draw_arcs(ax,sparcfire_r_arcs,sparcfire_r,\n",
    "                      colors=colors,lw=2,label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final task: we now want to use our trained classifier on our full sample of galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = Table.read('../../fits/sparcfire/sparcfire_samples.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_columns = ('in_sparcfire','in_volume_limit','in_mass_limit','in_spiral',\n",
    "               'axial_ok')\n",
    "in_ml_sample = np.all([samples[c] for c in mask_columns],axis=0)\n",
    "\n",
    "print('{} galaxies in the ML sample!'.format(in_ml_sample.sum()))\n",
    "ML_ids = gz2_data['dr8objid'][in_ml_sample]\n",
    "\n",
    "arc_tables_ML = []\n",
    "for id_ in ML_ids:\n",
    "    arc_tables_ML.append(ArcData(id_).arc_parameters(sparcfire_r_arcs,\n",
    "                                                   sparcfire_r))\n",
    "    \n",
    "arc_table_ML = vstack(arc_tables_ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arc_table_ML['p_good'] = np.zeros(len(arc_table_ML)) # dummy column!\n",
    "\n",
    "scaler, _, _ = ArcTable(arc_table_spotted).as_array(scaled=False)\n",
    "X_ML, y_ML, chi_mask_ML = ArcTable(arc_table_ML).as_array(scaler=scaler)\n",
    "\n",
    "y_predicted = best_clf.predict(X_ML)\n",
    "y_predicted[chi_mask_ML == False] = 0\n",
    "print('Predicted {}/{} good arcs!'.format(y_predicted.sum(),\n",
    "                                          len(y_predicted)))\n",
    "\n",
    "arc_table_ML['p_good_predicted'] = y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = arc_table_ML.colnames\n",
    "dtypes = ('int64','int32','float32','float32','float32','float32',\n",
    "          'float32','float32','float32','bool','bool','bool','float32',\n",
    "          'float32','float32','float32','float32','float32','float32',\n",
    "          np.str,'bool','float32','float32','float32','float32')\n",
    "\n",
    "for column, dtype in zip(columns,dtypes):\n",
    "    arc_table_ML[column] = arc_table_ML[column].astype(dtype)\n",
    "\n",
    "arc_table_ML.write('arc_table_ML.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
